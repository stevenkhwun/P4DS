---
title: "Running SQL using <b>pandas</b>"
author: "SW"
date: "Last updated: `r Sys.Date()`"
output:
  html_document:
    toc: yes
    toc_depth: 2
    number_sections: yes
    toc_float:
      collapsed: no
      #smooth_scroll: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{python echo=FALSE}
import warnings
warnings.filterwarnings('ignore')
```


<div class="alert alert-block alert-info" style="margin-top: 20px">
<h5>Python method/function used</h5>

* <b>[pandas.DataFrame.drop_duplicates()](#dropduplicates)</b>
* <b>[pandas.DataFrame.head()](#head)</b>
* <b>[pandas.DataFrame.nlargest()](#nlargest)</b>
* <b>[pandas.DataFrame.loc\[\]](#loc)</b>

</div>

<hr>

<font size="6">Introduction</font>

(This page is adapted from pandas' [Comparison with SQL](https://pandas.pydata.org/docs/getting_started/comparison/comparison_with_sql.html#) and a Medium article [Pandas equivalent of 10 useful SQL queries](https://towardsdatascience.com/pandas-equivalent-of-10-useful-sql-queries-f79428e60bd9) by _Dorian Lazar_.)

This page is meant to provide some examples of how various SQL operations would be performed using pandas.

As is customary, we import pandas and NumPy as follows:

```{python}
import pandas as pd
import numpy as np
```

Most of the examples will utilize the `tips` dataset found within pandas tests. We’ll read the data into a `DataFrame` called `tips` and assume we have a database table of the same name and structure.

```{python}
url = (
    "https://raw.githubusercontent.com/pandas-dev"
    "/pandas/main/pandas/tests/io/data/csv/tips.csv"
    )

tips = pd.read_csv(url)
tips.head(5)
```

We will also use the `usvideos` dataset in some examples.

```{python}
usvideos_url = (
"https://raw.githubusercontent.com/OrysyaStus/SeismicBlog/master/Data_Visualizations"
"/Dynamic_Visuals_Using_Date_Range_Slicers_Pt1/data/USvideos.csv"
)
usvideos = pd.read_csv(usvideos_url)
usvideos.head()
```
 
 
# Copies vs. in place operations

Most pandas operations return copies of the `Series`/`DataFrame`. To make the changes “stick”, you’ll need to either assign to a new variable:

```{python eval=FALSE}
# assign to a new variable
sorted_df = df.sort_values("col1")
```

or overwrite the original one:

```{python eval=FALSE}
df = df.sort_values("col1")
```


# SELECT

In SQL, selection is done using a comma-separated list of columns you’d like to select (or a * to select all columns):


```sql
SELECT total_bill, tip, smoker, time
FROM tips;
```

With pandas, column selection is done by passing a list of column names to your DataFrame:

```{python}
tips[["total_bill", "tip", "smoker", "time"]]
```

Calling the `DataFrame` without the list of column names would display all columns (akin to SQL’s *).

## SELECT DISTINCT{#dropduplicates}

The <b>SELECT DISTINCT</b> statement returns only unique rows from a table. In a data frame there may be duplicate values. If you want to get only distinct rows (remove duplicates) it is as simple as calling the `.drop_duplicates()` method.

```{python}
tips[['sex']].drop_duplicates()
```

## LIMIT{#head}

```sql
SELECT TOP number col1, col2, ... FROM table
```

or

```sql
SELECT col1, col2, ... FROM table LIMIT number
```

The <b>TOP</b> or <b>LIMIT</b> keyword in SQL is used to limit the number of returned rows from the top of the table.

In pandas this is very easy to do with `.head(number)` method. Pandas also has the `.tail(number)` method for showing the rows from the end of data frame.

For example, to execute the following SQL queries:

```sql
SELECT * FROM tips
LIMIT 5;
```

We can simple run the following code:

```{python}
tips.head(5)
```

## Top n rows with OFFSET{#nlargest}

In SQL, we use <b>OFFSET</b> to skip the first n rows from displaying. For example, if we want to inspect from the 11th entry of the table, we can use <b>OFFSET 10</b>.

In pandas, we can do similar thing by using <b>.nlargest()</b> method. However, we can only act on the columns which can be ordered and only displayed the ordered table.

For example, the following SQL code displays a table which lists 10 entries started from the 6th largest tips:

```sql
SELECT * FROM tips
ORDER BY tip DESC
LIMIT 10 OFFSET 5;
```

We can do this in pandas by the following codes:

```{python}
tips.nlargest(10 + 5, columns="tip").tail(10)
```

In fact, the above code select the top 16 (10 + 5) rows according to the amount of tips received. However, it only display the last 10 rows (`.tail(10)`). Effectively, the code give a table of 10 larg tips starting from the 6th largest.

We can do similar operation with the `.nsmallest()` method. We can find more information on the website of pandas for [pandas.DataFrame.nlargest](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nlargest.html) and [pandas.DataFrame.nsmallest](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.nsmallest.html) methods.


## Add a calculated column

In SQL, you can add a calculated column:

```sql
SELECT *, tip/total_bill as tip_rate
FROM tips;
```

With pandas, you can use the `DataFrame.assign()` method of a `DataFrame` to append a new column:

```{python}
tips.assign(tip_rate=tips['tip'] / tips['total_bill'])
```

# WHERE

## Boolean indexing

Filtering in SQL is done via a WHERE clause.

```sql
SELECT *
FROM tips
WHERE time = 'Dinner';
```
DataFrames can be filtered in multiple ways; the most intuitive of which is using _**boolean indexing**_.

```{python}
tips[tips["time"] == "Dinner"].head(5)
```

The above statement is simply passing a Series of True/False objects to the DataFrame, returning all row with True.

```{python}
is_dinner = tips["time"] == "Dinner"
is_dinner
```

```{python}
is_dinner.value_counts()
```

```{python}
tips[is_dinner]
```

Following is an alternative way using `df.loc`{#loc} method, which can specify the columns to be included in the output.

```sql
SELECT total_bill, tip, time, size 
FROM tips
WHERE time = 'Dinner';
```

```{python}
tips.loc[tips["time"]=="Dinner", ["total_bill", "tip", "time", "size"]]
```

## <b>OR</b> and <b>AND</b>

Just like SQL's `OR` and `AND`, multiple conditions can be passed to a DataFrame using `|` (`OR`) and `&` (`AND`).

Tips of more than $5 at Dinner meals:

```sql
SELECT *
FROM tips
WHERE time = 'Dinner' AND tip > 5.00;
```

```{python}
tips[(tips["time"] == "Dinner") & (tips["tip"] > 5.00)]
```

Tips by parties of at least 5 diners OR bill total was more than $45:

```sql
SELECT *
FROM tips
WHERE size >= 5 OR total_bill > 45;
```

```{python}
tips[(tips["size"] >= 5) | (tips["total_bill"] > 45)]
```

## NULL checking

NULL checking is done using the `notna()` and `isna()` mehtods.

```{python}
frame = pd.DataFrame(
    {"col1": ["A", "B", np.NaN, "C", "D"], "col2": ["F", np.NaN, "G", "H", "I"]}
    )
frame
```

Assume we have a table of the same structure as our DataFrame above. We can see on the records wher `col2` IS NULL with the following query:

```sql
SELECT *
FROM frame
WHERE col2 IS NULL;
```

```{python}
frame[frame["col2"].isna()]
```

Getting items where `col1` IS NOT NULL can be done with `notna()`.

```sql
SELECT *
FROM frame
WHERE col1 IS NOT NULL;
```

```{python}
frame[frame["col1"].notna()]
```
